# MedVis3D - AI-Powered Medical Image 3D Visualization

<p align="center">
  <strong>Transform 2D medical images into interactive 3D visualizations using client-side AI</strong>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Next.js-16.0-black" alt="Next.js 16" />
  <img src="https://img.shields.io/badge/TypeScript-5.0-blue" alt="TypeScript" />
  <img src="https://img.shields.io/badge/React-19-61dafb" alt="React 19" />
  <img src="https://img.shields.io/badge/Three.js-R3F-black" alt="Three.js" />
  <img src="https://img.shields.io/badge/ONNX_Runtime-WebGPU-orange" alt="ONNX Runtime" />
</p>

---

## ğŸ¯ Overview

MedVis3D is a **privacy-first**, browser-based medical visualization tool that converts 2D medical images (X-rays, CT slices, MRI) into interactive 3D topological visualizations using the **Depth Anything V2** AI model.

**Key Value Proposition:**
- ğŸ”’ **100% Client-Side** - PHI never leaves the patient's device
- âš¡ **WebGPU Accelerated** - Near-native AI inference in browser
- ğŸ“± **Mobile Ready** - Works on iOS Safari and Android Chrome
- ğŸ¥ **HIPAA Friendly** - Zero server-side data processing

---

## âœ¨ Features

### Implemented âœ…

| Category | Feature | Status |
|----------|---------|--------|
| **Input** | JPEG/PNG Upload | âœ… |
| | DICOM P10 Parsing | âœ… |
| | Camera Capture (Mobile) | âœ… |
| | Multi-frame DICOM | âœ… |
| | Video Frame Extraction | âœ… |
| **AI** | Depth Anything V2 Inference | âœ… |
| | WebGPU Backend | âœ… |
| | WASM Fallback | âœ… |
| | Model Caching (Cache API) | âœ… |
| **3D Viewer** | Displacement Mesh Rendering | âœ… |
| | OrbitControls (Rotate/Pan/Zoom) | âœ… |
| | Depth Intensity Slider | âœ… |
| | Wireframe Toggle | âœ… |
| | Screenshot Export | âœ… |
| **Tools** | Annotation (Circle/Arrow/Text/Freehand) | âœ… |
| | PDF Report Export | âœ… |
| | AI Report Generation | âœ… |
| | QR Code Sharing | âœ… |
| | Session Persistence | âœ… |
| **Integration** | SMART on FHIR (EHR Launch) | âœ… |
| | i18n (English/Spanish) | âœ… |
| **UX** | Keyboard Shortcuts | âœ… |
| | Fullscreen Mode | âœ… |
| | Mobile Responsive | âœ… |
| | Memory Management | âœ… |

### Pending ğŸ“‹

| Feature | Priority | Notes |
|---------|----------|-------|
| Real LLM API Integration | P2 | Currently template-based |
| Anatomy Auto-Labeling | P2 | Requires vision model |
| Multi-language (FR/DE/ZH) | P3 | i18n ready |
| PWA Offline Mode | P3 | Service worker needed |

---

## ğŸš€ Quick Start

### Prerequisites

- Node.js 18+ 
- npm 9+
- Modern browser (Chrome 113+, Edge, Firefox 141+, Safari 18+)

### Installation

```bash
# Clone repository
git clone https://github.com/yourusername/medical_imaging3D.git
cd medical_imaging3D

# Install dependencies
npm install

# Download AI model (REQUIRED)
# Place in: public/models/depth-anything-v2-small.onnx
# Download from: https://huggingface.co/depth-anything/Depth-Anything-V2-Small-hf

# Start development server
npm run dev
```

Open [http://localhost:3000](http://localhost:3000) in your browser.

### Production Build

```bash
npm run build
npm start
```

### Deploy to Vercel

```bash
npm i -g vercel
vercel
```

---

## ğŸ“ Project Structure

```
src/
â”œâ”€â”€ app/                    # Next.js App Router
â”‚   â”œâ”€â”€ page.tsx           # Main application page
â”‚   â”œâ”€â”€ layout.tsx         # Root layout
â”‚   â”œâ”€â”€ providers.tsx      # Context providers
â”‚   â””â”€â”€ sections/          # Page sections
â”‚       â”œâ”€â”€ HeroSection.tsx
â”‚       â”œâ”€â”€ UploadSection.tsx
â”‚       â”œâ”€â”€ InferenceSection.tsx
â”‚       â””â”€â”€ ViewerSection.tsx
â”‚
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ common/            # Shared components
â”‚   â”œâ”€â”€ layout/            # Header, Footer, etc.
â”‚   â””â”€â”€ ui/                # shadcn/ui components
â”‚
â”œâ”€â”€ features/              # Feature modules
â”‚   â”œâ”€â”€ ai-assistant/      # AI report generation
â”‚   â”œâ”€â”€ annotation/        # Drawing tools
â”‚   â”œâ”€â”€ camera/            # Camera capture
â”‚   â”œâ”€â”€ dicom/             # DICOM parsing
â”‚   â”œâ”€â”€ export/            # PDF/screenshot export
â”‚   â”œâ”€â”€ fhir/              # SMART on FHIR
â”‚   â”œâ”€â”€ inference/         # ONNX Runtime hooks
â”‚   â”œâ”€â”€ session/           # Persistence
â”‚   â”œâ”€â”€ sharing/           # QR/URL sharing
â”‚   â”œâ”€â”€ video/             # Video processing
â”‚   â””â”€â”€ viewer/            # 3D viewer (R3F)
â”‚
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ i18n/              # Internationalization
â”‚   â”œâ”€â”€ onnx/              # ONNX model loading
â”‚   â””â”€â”€ utils/             # Utilities
â”‚
â””â”€â”€ stores/                # Zustand state
```

---

## ğŸ”§ Configuration

### Environment Variables

Create `.env.local` (optional):

```env
# For future LLM integration
NEXT_PUBLIC_OPENAI_API_KEY=sk-...
NEXT_PUBLIC_ANTHROPIC_API_KEY=sk-...
```

### AI Model Setup

**Required:** Download the ONNX model file:

1. Visit [Hugging Face - Depth Anything V2](https://huggingface.co/depth-anything/Depth-Anything-V2-Small-hf)
2. Download `depth-anything-v2-small.onnx` (~50MB)
3. Place in `public/models/depth-anything-v2-small.onnx`

---

## âŒ¨ï¸ Keyboard Shortcuts

| Key | Action |
|-----|--------|
| `R` | Reset view |
| `W` | Toggle wireframe |
| `F` | Toggle fullscreen |
| `âŒ˜/Ctrl + S` | Save screenshot |
| `â†‘` / `â†“` | Adjust depth intensity |
| `Esc` | Exit fullscreen |

---

## ğŸ›¡ï¸ Security & Privacy

- **Zero PHI Upload** - All AI processing happens in browser
- **No Server Storage** - Images never leave device
- **HIPAA Architecture** - Privacy-by-design
- **CSP Headers** - XSS protection configured
- **No PII Logging** - Clean audit trail

---

## ğŸ“Š Performance Benchmarks

| Metric | WebGPU | WASM Fallback |
|--------|--------|---------------|
| Inference Time | 500ms-1.2s | 2-4s |
| Memory Usage | ~150-200MB | ~100-150MB |
| Frame Rate | 60 FPS | 60 FPS |
| Model Load (cached) | <100ms | <100ms |

---

## ğŸ§ª Testing

```bash
# Run linter
npm run lint

# Type check
npx tsc --noEmit
```

---

## ğŸ“š Documentation

| Document | Description |
|----------|-------------|
| [PRD](docs/prd_org.md) | Product Requirements |
| [Design Guidelines](docs/design_guidelines.md) | UI/UX Standards |
| [Gap Analysis](docs/GAP_ANALYSIS.md) | Implementation Status |
| [Progress Update](progress_update.md) | Development Log |

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing`)
5. Open Pull Request

---

## ğŸ“„ License

This project is for educational purposes. See [LICENSE](LICENSE) for details.

---

## âš ï¸ Disclaimer

**This software is for EDUCATIONAL and COMMUNICATION purposes only.**

- NOT intended for medical diagnosis
- NOT cleared by FDA for clinical use
- Always consult qualified healthcare professionals

---

## ğŸ™ Acknowledgments

- [Depth Anything V2](https://github.com/DepthAnything/Depth-Anything-V2) - AI Model
- [ONNX Runtime Web](https://onnxruntime.ai/) - Browser Inference
- [React Three Fiber](https://docs.pmnd.rs/react-three-fiber) - 3D Rendering
- [shadcn/ui](https://ui.shadcn.com/) - UI Components
- [Cornerstone.js](https://cornerstonejs.org/) - DICOM Support
